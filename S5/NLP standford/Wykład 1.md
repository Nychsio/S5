
## NLP overivew
### Evaluation metrcs

**Accuracy **
% obserawcji został przewidziany poprawnie

- **Precision**
	- % spośród fwszystkich  pozytywnych które były poprawne 
- **Recall**

	- % prawidziwe pozytywnych które były pozytywne
- **F1 score**
	- funkcja precyzji i recall
### Machine Translation

-Bule

-rougef
- **Perplexity** qunatifies how suprised the model is to see some words
only looks on outputs 



## Tokenization



 

| arbitary | A   | cute | teddy bear | is   | reading | .       |      |       |     |
| -------- | --- | ---- | ---------- | ---- | ------- | ------- | ---- | ----- | --- |
| word     | A   | cute | teddy      | bear | is      | reading | .    |       |     |
| sub-word | A   | cute | ted        | ##dy | bear    | is      | read | ##ing | .   |
|          |     |      |            |      |         |         |      |       |     |


w sub word może nie rozpoznąc pomyłek ale więcej tokenów



podobność wektorów to = cosine similarity


subowrd is a nice tradeoff between recogintion roots of words adn


f
f